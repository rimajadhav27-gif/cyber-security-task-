import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# Function to get all forms from a webpage
def get_forms(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    return soup.find_all("form")

# Function to get form details
def get_form_details(form):
    details = {}
    details["action"] = form.attrs.get("action")
    details["method"] = form.attrs.get("method", "get").lower()
    inputs = []
    for input_tag in form.find_all("input"):
        inputs.append({
            "name": input_tag.attrs.get("name"),
            "type": input_tag.attrs.get("type", "text")
        })
    details["inputs"] = inputs
    return details

# Test the functions
if __name__ == "__main__":
    target_url = input("Enter target URL (your test page): ")
    forms = get_forms(target_url)
    print(f"Found {len(forms)} form(s) on the page.")
    for i, form in enumerate(forms, start=1):
        print(f"\nForm {i} details:")
        print(get_form_details(form))
